{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run init.ipy\n",
    "from utils import *\n",
    "import miregularizer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import load_mnist_rnn\n",
    "d=load_mnist_rnn(max_train_items=2000, max_test_items=2000, normalize=False)\n",
    "noiselayer, kdelayer = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import RepeatVector, TimeDistributed # Dense, Dropout, Activation, , , \n",
    "from rnn import NoInputRNN\n",
    "\n",
    "macro_dims = 15\n",
    "num_output_vars, num_timesteps, num_input_vars = d.train.Y.shape[2], d.train.Y.shape[1], d.train.X.shape[1]\n",
    "act1, act2, act3 = 'tanh', 'tanh', 'tanh'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(macro_dims, activation=act1, input_dim=num_input_vars))\n",
    "kdelayer, noiselayer = None, None\n",
    "if True:\n",
    "    kdelayer   = miregularizer2.KDEParamLayer(init_logvar=-5)\n",
    "    noiselayer = miregularizer2.GaussianNoise2(d.train, init_logvar=-5, kdelayer=kdelayer, regularizemi=True, init_alpha=0.)\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(kdelayer)\n",
    "    model.add(noiselayer)\n",
    "\n",
    "model.add(RepeatVector(1))\n",
    "# noise plus mi layer\n",
    "\n",
    "model.add(NoInputRNN(output_dim=macro_dims, num_timesteps=num_timesteps))\n",
    "\n",
    "#model.add(TDD(Dense(macro_dims, activation=act1), input_shape=(num_timesteps,num_input_vars)))\n",
    "#model.add(rnn_w_noise(macro_dims, \n",
    "#                      U_regularizer=regobj, \n",
    "#                      activity_regularizer=regact, \n",
    "#                      return_sequences=True, \n",
    "#                      activation=act2,\n",
    "#                      sigma=.1\n",
    "#                     ))\n",
    "model.add(TimeDistributed(Dense(num_output_vars, activation=act3)))\n",
    "\n",
    "kdetraincb, noisetraincb, reportcb = None, None, None\n",
    "if noiselayer is not None and kdelayer is not None:\n",
    "    kdetraincb   = miregularizer2.KDETrain(traindata=d.train, kdelayer=kdelayer)\n",
    "    noisetraincb = miregularizer2.NoiseTrain(traindata=d.train, noiselayer=noiselayer)\n",
    "    reportcb     = miregularizer2.ReportVars(noiselayer=noiselayer, kdelayer=kdelayer)\n",
    "\n",
    "\n",
    "#model.compile(loss='mse', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compilefunc():\n",
    "    model.compile(loss='mse', optimizer='rmsprop')\n",
    "    if noiselayer is not None:\n",
    "        K.set_value(noiselayer.logvar, -10)\n",
    "    if kdelayer is not None:\n",
    "        K.set_value(kdelayer.logvar, -10)\n",
    "    \n",
    "compilefunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%timeit -n 1 -r 1\n",
    "if True:\n",
    "    batch_size = 10\n",
    "    nbepoch = 100\n",
    "\n",
    "    cbs = []\n",
    "    if reportcb is not None:\n",
    "        cbs.append(reportcb)\n",
    "        \n",
    "    if noiselayer is not None:\n",
    "        K.set_value(noiselayer.alpha, 0.0)\n",
    "\n",
    "    inithist = model.fit(d.train.X, d.train.Y, nb_epoch=nbepoch,\n",
    "                     batch_size=batch_size, verbose=2, # validation_split=0.1, \n",
    "                     callbacks=cbs)\n",
    "\n",
    "    model.save_weights(\"models/rnnfitmodel.h5\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#alphavals = np.linspace(0, 5, 20, endpoint=True)\n",
    "#alphavals = np.exp(np.linspace(0, np.log(6), 20, endpoint=True))-1\n",
    "alphavals = np.exp(np.linspace(0, np.log(1.01), 10, endpoint=True))-1\n",
    "\n",
    "nbepoch = 50\n",
    "batch_size = 10\n",
    "if 'saved_hist' not in locals():\n",
    "    saved_hist = {}\n",
    "for alpha in alphavals: # [0.0001, 0.0002, 0.01, 0.2, 0.3] :\n",
    "    print \"**************** Doing alpha=%.5f ****************\" % alpha\n",
    "    if alpha in saved_hist:\n",
    "        continue\n",
    "    # Reset\n",
    "    #for clayer in model.layers:\n",
    "    #    clayer.build(clayer.input_shape)\n",
    "    \n",
    "    compilefunc()\n",
    "    model.load_weights(\"models/rnnfitmodel.h5\")\n",
    "    if noiselayer is not None :\n",
    "        K.set_value(noiselayer.alpha, alpha)\n",
    "\n",
    "    hist = model.fit(d.train.X, d.train.Y, nb_epoch=nbepoch,\n",
    "                     batch_size=batch_size, verbose=2, # validation_split=0.1, \n",
    "                     callbacks=[kdetraincb, noisetraincb, reportcb,]\n",
    "                    )\n",
    "    saved_hist[alpha] = {'history':hist.history, 'endlogs': miregularizer2.get_logs(model, d, kdelayer, noiselayer)}\n",
    "    fname = \"models/rnnfitmodel%0.5f.h5\"%alpha\n",
    "    print \"saving to %s\"%fname\n",
    "    model.save_weights(fname)\n",
    "\n",
    "    print \n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "saved_hist2 = {}\n",
    "for k,v in saved_hist.iteritems():\n",
    "    if k > 0.01: \n",
    "        continue\n",
    "    saved_hist2[k] = v\n",
    "    \n",
    "with open('rnnsavedhist.dat', 'wb') as f:\n",
    "    cPickle.dump(saved_hist2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with open('rnnsavedhist.dat', 'rb') as f:\n",
    "#    saved_hist2 = cPickle.load(f)\n",
    "    \n",
    "matplotlib.rcParams.update({'font.size': 8, 'lines.linewidth':2})\n",
    "\n",
    "alphavals, mivalstst, mivalstrn, klvalstst, klvalstrn = [], [], [], [], []\n",
    "\n",
    "for alpha in sorted(saved_hist.keys()):\n",
    "    if alpha >= 0.015: \n",
    "        continue\n",
    "    hist = saved_hist[alpha]['endlogs']\n",
    "    #ndx = -1 # np.argmin( hist['val_loss'] )\n",
    "    alphavals.append(alpha)\n",
    "    mivalstrn.append(hist['mi_trn'])\n",
    "    mivalstst.append(hist['mi_tst'])\n",
    "    klvalstst.append(hist['kl_tst'])\n",
    "    klvalstrn.append(hist['kl_trn'])\n",
    "    #valloss.append(hist['val_loss'][ndx])\n",
    "    #print ndx\n",
    "    \n",
    "alphavals, mivalstst, mivalstrn, klvalstst, klvalstrn = map(np.array, [alphavals, mivalstst, mivalstrn, klvalstst, klvalstrn])\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.subplot(1,4,1)\n",
    "plt.scatter(alphavals, mivalstrn)\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('MI-train')\n",
    "plt.xlim([0, .01])\n",
    "plt.ylim([0, plt.ylim()[1]])\n",
    "plt.subplot(1,4,2)\n",
    "plt.scatter(alphavals, mivalstst)\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('MI-test')\n",
    "plt.xlim([0, .01])\n",
    "plt.ylim([0, plt.ylim()[1]])\n",
    "plt.subplot(1,4,3)\n",
    "plt.scatter(alphavals, klvalstrn)\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('KL-train')\n",
    "plt.xlim([0, .01])\n",
    "plt.subplot(1,4,4)\n",
    "plt.scatter(alphavals, klvalstst)\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('KL-test')\n",
    "plt.xlim([0, .01])\n",
    "\n",
    "#plt.subplot(1,4,4)\n",
    "#plt.scatter(alphavals, valloss)\n",
    "#plt.xlabel('alpha')\n",
    "#plt.ylabel('Valloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print alphavals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "#with plt.style.context([u'seaborn-paper']):\n",
    "if True:\n",
    "    fig=plt.figure(figsize=(13,4))\n",
    "    matplotlib.rcParams.update({'font.size': 16, 'lines.linewidth':2})\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ln2 = np.log(2)\n",
    "    print ln2*mivalstrn\n",
    "    plt.plot(ln2*mivalstrn,ln2*klvalstrn)\n",
    "    plt.xlabel('MI (bits)')\n",
    "    plt.ylabel('KL (bits)')\n",
    "    plt.title('Training dataset')\n",
    "    ax2 = fig.add_subplot(122, sharey=ax1)\n",
    "    plt.plot(ln2*mivalstst, ln2*klvalstst)\n",
    "    plt.xlabel('MI (bits)')\n",
    "    plt.ylabel('KL (bits)')\n",
    "    plt.title('Testing dataset')\n",
    "\n",
    "plt.savefig('imgs/mnist.pdf',bbox_inches='tight')\n",
    "#hist.history # ['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "#with plt.style.context([u'seaborn-paper']):\n",
    "if True:\n",
    "    fig=plt.figure(figsize=(15,4))\n",
    "    matplotlib.rcParams.update({'font.size': 16, 'lines.linewidth':1.5})\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.plot(alphavals, mivalstrn, label='Training')\n",
    "    plt.xlabel(r'$\\alpha$')\n",
    "    plt.ylabel('MI (bits)')\n",
    "    plt.plot(alphavals, mivalstst, label='Testing')\n",
    "    plt.ylim([0,8])\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.plot(alphavals, klvalstrn, label='Training')\n",
    "    plt.xlabel(r'$\\alpha$')\n",
    "    plt.ylabel('KL (bits)')\n",
    "    plt.plot(alphavals, klvalstst, label='Testing')\n",
    "    plt.subplot(1,3,3)\n",
    "    \n",
    "    ln2 = np.log(2)\n",
    "    print ln2*mivalstrn\n",
    "    plt.plot(ln2*mivalstrn,ln2*klvalstrn, label='Training')\n",
    "    plt.xlabel('MI (bits)')\n",
    "    plt.ylabel('KL (bits)')\n",
    "    #plt.title('Training dataset')\n",
    "    #ax2 = fig.add_subplot(122, sharey=ax1)\n",
    "    plt.plot(ln2*mivalstst, ln2*klvalstst, label='Testing')\n",
    "    #plt.xlabel('MI (bits)')\n",
    "    #plt.ylabel('KL (bits)')\n",
    "    #plt.title('Testing dataset')\n",
    "    plt.legend()\n",
    "    fig.tight_layout()\n",
    "plt.savefig('imgs/mnist2.pdf',bbox_inches='tight')\n",
    "#hist.history # ['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#%%timeit -n 1 -r 1\n",
    "batch_size = 10\n",
    "callbacks = []\n",
    "if noiselayer is not None and kdelayer is not None:\n",
    "    noiselayer.alpha = 0.0\n",
    "    callbacks = [miregularizer2.KDETrain(traindata=d, model=model, kdelayer=kdelayer),\n",
    "                 miregularizer2.NoiseTrain(traindata=d, model=model, noiselayer=noiselayer),\n",
    "                 miregularizer2.ReportVars(traindata=d, noiselayer=noiselayer,kdelayer=kdelayer),\n",
    "                ]\n",
    "\n",
    "hist = model.fit(d.X_train, d.Y_train, nb_epoch=10,\n",
    "                 batch_size=batch_size, validation_split=0.1, verbose=2, \n",
    "                 callbacks=callbacks)\n",
    "#print hist.history\n",
    "\"\"\"\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for l, v in hist.history.iteritems():\n",
    "    plt.figure()\n",
    "    plt.plot(v)\n",
    "    plt.title(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#fitmodel1.00000.h5\n",
    "#activity = {}\n",
    "for fname in [\"fitmodel1.50000.h5\",]:#\"fitmodel.h5\", \"fitmodel1.00000.h5\", \"fitmodel2.00000.h5\"]:\n",
    "    compilefunc()\n",
    "    model.load_weights(fname)\n",
    "\n",
    "    #activity = get_activations(model, -2, d.X_train)[0]\n",
    "    #get_activations = K.function([model.layers[0].input, K.learning_phase()], [noiselayer.output,])\n",
    "    #activations = get_activations([X_batch,0])\n",
    "    #activity = get_activations([d.X_train, 1])\n",
    "    #plt.figure()\n",
    "    #plot_activity(activity, colors=d.y_train, size=1) # , doPCA=False)\n",
    "    get_activations = K.function([model.layers[0].input, K.learning_phase()], [noiselayer.input,])\n",
    "    activity[fname]=get_activations([d.X_train,])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,4))\n",
    "for ndx, fname in enumerate([\"fitmodel.h5\", \"fitmodel1.00000.h5\",\"fitmodel2.00000.h5\"]): #\"fitmodel1.50000.h5\", \n",
    "    ax = fig.add_subplot(131+ndx, projection='3d')\n",
    "    #plt.subplot(1,4,ndx+1)\n",
    "    plot_activity(activity[fname], doPCA=True, colors=d.y_train, size=2, dims=3, opts=dict(whiten=True))\n",
    "    plt.title(r'$\\alpha = %d$' %ndx)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "#plt.savefig('imgs/hidden.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(d2.X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(activity[:,0],activity[:,1])\n",
    "plt.xlim([-1.5,1.5])\n",
    "plt.ylim([-1.5,1.5])\n",
    "plt.figure()\n",
    "plt.plot(np.var(activity, axis=0))\n",
    "plt.ylim([0, plt.ylim()[1]])\n",
    "\n",
    "\"\"\"\n",
    "f1 = K.function([model.layers[0].input, K.learning_phase()], [noiselayer.input])\n",
    "x1=f1([d.X_train, 0])[0]\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig=plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "import sklearn.decomposition\n",
    "\n",
    "x2 = sklearn.decomposition.PCA(3, whiten=True).fit_transform(x1)\n",
    "plt.scatter(x2[:,0], x2[:,1], zs=x2[:,2], c=d.y_train, edgecolor='none')\n",
    "print x2.shape\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#adict = {}\n",
    "#adict['noreg'] = get_activations(model, 0, X_train)[0]\n",
    "#adict['entropyonly'] = get_activations(model, 0, X_train)[0]\n",
    "#adict['mionly'] = get_activations(model, 0, X_train)[0]\n",
    "#adict['entropynnoise'] = get_activations(model, 0, X_train)[0]\n",
    "#adict['minnoise'] = get_activations(model, 0, X_train)[0]\n",
    "#adict['fixednoise'] = get_activations(model, 0, X_train)[0]\n",
    "#adict['mifixednoise'] = get_activations(model, 0, X_train)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k,v in adict.iteritems():\n",
    "    plot_activity(v)\n",
    "    plt.title(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Kdists = K.placeholder(ndim=2)\n",
    "Klogvar = K.placeholder(ndim=0)\n",
    "from miregularizer2 import kde_entropy_from_dists_loo\n",
    "N = 1000\n",
    "dims = 10\n",
    "lossfunc = K.function([Kdists, Klogvar,], [kde_entropy_from_dists_loo(Kdists, N, dims, K.exp(Klogvar))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lossfunc([np.eye(N),1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(np.array([1])) # [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fh=K.function([model.layers[0].input,],[noiselayer.mi_obj.get_h()])\n",
    "f = K.function([model.layers[0].input,],[noiselayer.input])\n",
    "#.mi_obj.get_h()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx=f([d.X_train,])\n",
    "print xx\n",
    "print fh([d.X_train,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K.eval(K.exp(noiselayer.logvar)+K.exp(noiselayer.kdelayer.logvar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v=K.placeholder(ndim=2)\n",
    "lv=K.placeholder(ndim=0)\n",
    "from miregularizer2 import kde_entropy # , get_dims\n",
    "f2 = K.function([v,lv],[kde_entropy(v,lv)]) # [noiselayer.mi_obj.get_h()])kde_entropy(self.layer.input, totalvar\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print xx[0].shape\n",
    "f2([xx[0],1.])\n",
    "#import theano\n",
    "#theano.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alphavals = np.exp(np.linspace(0, np.log(1.1), 30, endpoint=True))-1\n",
    "print alphavals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f1(output):\n",
    "    y1 = K.expand_dims(output, 0)\n",
    "    y2 = K.expand_dims(output, 1)\n",
    "\n",
    "    dists = K.sum(K.square(y1-y2), axis=2) \n",
    "    return dists\n",
    "#l2diff = tf.sqrt( tf.reduce_sum(tf.square(tf.sub(x1, x2)),\n",
    "#                                reduction_indices=1))\n",
    "in1 = K.placeholder()\n",
    "f1k = K.function([in1], [f1(in1)])\n",
    "import tensorflow as tf\n",
    "def f2(x):\n",
    "    #x1 = K.expand_dims(output, 0)\n",
    "    #x2 = K.expand_dims(output, 1)\n",
    "\n",
    "    #dists = K.sum(K.square(y1-y2), axis=2) \n",
    "    #dists = tf.reduce_sum(tf.square(tf.sub(x1, x2)),reduction_indices=2)\n",
    "    \n",
    "    x2 = K.expand_dims(K.sum(K.square(x), axis=1), 1)\n",
    "    #x2 = x2 + K.transpose(x2)\n",
    "    #return K.shape(x2)\n",
    "    xy = K.dot(x, K.transpose(x))\n",
    "    dists = x2 + K.transpose(x2) - 2*xy\n",
    "\n",
    "    return dists\n",
    "#in1 = K.placeholder()\n",
    "f2k = K.function([in1], [f2(in1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rrr=np.random.random((2000,50))\n",
    "#print f1k([rrr,])\n",
    "print f2k([rrr,])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compilefunc()\n",
    "model.load_weights(\"models/rnnfitmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndxs = [6,]# np.arange(1, dtype='int')\n",
    "x,y = d.X_test, d.Y_test\n",
    "#x,y = d.X_train, d.Y_train\n",
    "for i,actual in zip(model.predict(x[ndxs]),y[ndxs]):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(actual.reshape([20,28]), interpolation='nearest',cmap='Greys', aspect='auto')\n",
    "    plt.xticks([])\n",
    "    plt.title('Ground Truth')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(i.reshape([20,28]), interpolation='nearest', cmap='Greys', aspect='auto')\n",
    "    plt.xticks([])\n",
    "    plt.title('Predicted')\n",
    "plt.savefig('imgs/imgtask.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
